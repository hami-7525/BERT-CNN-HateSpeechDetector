This project tackles the spread of hate speech and offensive language in online comments using a hybrid BERT-CNN model. By training on a diverse dataset of labeled comments, the system accurately classifies offensive and normal discourse. The BERT-CNN architecture, enhanced with advanced preprocessing and evaluation metrics like accuracy, precision, recall, and F1 score, aims to foster safer online communities by providing a powerful tool for identifying harmful language patterns.


Result
Achieving an 88% accuracy rate in our hate speech detection project is a significant
milestone. This impressive accuracy indicates that our BERT+CNN model effectively
distinguishes between offensive language and normal language in comments. With such
high accuracy, our model demonstrates its ability to accurately classify comments, which is
crucial for online platforms to filter out harmful content and ensure a safer online environment.
Furthermore, we can delve deeper into other evaluation metrics like precision, recall, and
F1 score to gain a comprehensive understanding of our model’s performance across various
classes. Overall, our model’s 88% accuracy underscores its effectiveness in identifying hate
speech and contributes to efforts aimed at curbing the dissemination of harmful content online
